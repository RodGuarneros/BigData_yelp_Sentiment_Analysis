{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive_review.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nteract": {
      "version": "0.11.2"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodGuarneros/BigData_yelp_Sentiment_Analysis/blob/main/naive_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUVgL1wNNajZ",
        "outputId": "19254865-9b77-4ce7-d125-f0f2123af198"
      },
      "source": [
        "import os\n",
        "# Find the version of spark 3.0 form http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "#spark_version 3.0.2\n",
        "spark_version = \"spark-3.1.1\"\n",
        "os.environ[\"SPARK_VERSION\"] = spark_version\n",
        "\n",
        "# Install Java, Spark, and Findspark\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [1 InRelease 0 B/3,\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connecting to ppa.\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connecting to ppa.\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [53.9 kB]\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [770 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,119 kB]\n",
            "Get:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [399 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [24.7 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,410 kB]\n",
            "Get:21 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,181 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,759 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [31.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [429 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,550 kB]\n",
            "Get:27 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [900 kB]\n",
            "Get:28 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Get:29 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [53.2 kB]\n",
            "Fetched 13.0 MB in 5s (2,623 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylRn3V5sBWL4"
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnI0zdY5NYCJ",
        "outputId": "6da20a04-1eb2-41d1-fcf7-2fdb2bff877e"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://s3.amazonaws.com/dataviz-curriculum/day_2/yelp_reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"yelp_reviews.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show(truncate=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------------------------------------------------------------------------------------------------------+\n",
            "|class   |text                                                                                                           |\n",
            "+--------+---------------------------------------------------------------------------------------------------------------+\n",
            "|positive|Wow... Loved this place.                                                                                       |\n",
            "|negative|Crust is not good.                                                                                             |\n",
            "|negative|Not tasty and the texture was just nasty.                                                                      |\n",
            "|positive|Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.                        |\n",
            "|positive|The selection on the menu was great and so were the prices.                                                    |\n",
            "|negative|Now I am getting angry and I want my damn pho.                                                                 |\n",
            "|negative|Honeslty it didn't taste THAT fresh.)                                                                          |\n",
            "|negative|The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.|\n",
            "|positive|The fries were great too.                                                                                      |\n",
            "|positive|A great touch.                                                                                                 |\n",
            "|positive|Service was very prompt.                                                                                       |\n",
            "|negative|Would not go back.                                                                                             |\n",
            "|negative|The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.            |\n",
            "|positive|I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!                                                    |\n",
            "|negative|I was disgusted because I was pretty sure that was human hair.                                                 |\n",
            "|negative|I was shocked because no signs indicate cash only.                                                             |\n",
            "|positive|Highly recommended.                                                                                            |\n",
            "|negative|Waitress was a little slow in service.                                                                         |\n",
            "|negative|This place is not worth your time, let alone Vegas.                                                            |\n",
            "|negative|did not like at all.                                                                                           |\n",
            "+--------+---------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1sIVDLGYemT",
        "outputId": "cadcd3eb-db8d-48ac-ff80-332d1c19db5c"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BbzYExyNYCR",
        "outputId": "cb32e20d-6a04-4188-f090-004139a42e04"
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "data_df = df.withColumn('length', length(df['text']))\n",
        "data_df.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+------+\n",
            "|   class|                text|length|\n",
            "+--------+--------------------+------+\n",
            "|positive|Wow... Loved this...|    24|\n",
            "|negative|  Crust is not good.|    18|\n",
            "|negative|Not tasty and the...|    41|\n",
            "|positive|Stopped by during...|    87|\n",
            "|positive|The selection on ...|    59|\n",
            "|negative|Now I am getting ...|    46|\n",
            "|negative|Honeslty it didn'...|    37|\n",
            "|negative|The potatoes were...|   111|\n",
            "|positive|The fries were gr...|    25|\n",
            "|positive|      A great touch.|    14|\n",
            "|positive|Service was very ...|    24|\n",
            "|negative|  Would not go back.|    18|\n",
            "|negative|The cashier had n...|    99|\n",
            "|positive|I tried the Cape ...|    59|\n",
            "|negative|I was disgusted b...|    62|\n",
            "|negative|I was shocked bec...|    50|\n",
            "|positive| Highly recommended.|    19|\n",
            "|negative|Waitress was a li...|    38|\n",
            "|negative|This place is not...|    51|\n",
            "|negative|did not like at all.|    20|\n",
            "+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od7Qj0sxNYCW"
      },
      "source": [
        "### Feature Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59dwxefsNYCX"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label') # zeros and ones\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yssO0_Q5NYCb"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_YyUpR3NYCf"
      },
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBViHQOaNYCj"
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDODyxF7NYCn",
        "outputId": "1c854b2c-fbb1-40f7-b30d-63b5dc91dd73"
      },
      "source": [
        "# Show label and resulting features\n",
        "cleaned.select(['label', 'features', 'length']).show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+------+\n",
            "|label|            features|length|\n",
            "+-----+--------------------+------+\n",
            "|  1.0|(262145,[108541,1...|    24|\n",
            "|  0.0|(262145,[49815,10...|    18|\n",
            "|  0.0|(262145,[95889,97...|    41|\n",
            "|  1.0|(262145,[9056,531...|    87|\n",
            "|  1.0|(262145,[15370,67...|    59|\n",
            "|  0.0|(262145,[19036,98...|    46|\n",
            "|  0.0|(262145,[30950,48...|    37|\n",
            "|  0.0|(262145,[15494,58...|   111|\n",
            "|  1.0|(262145,[53777,95...|    25|\n",
            "|  1.0|(262145,[107107,2...|    14|\n",
            "|  1.0|(262145,[43756,99...|    24|\n",
            "|  0.0|(262145,[127310,1...|    18|\n",
            "|  0.0|(262145,[407,1903...|    99|\n",
            "|  1.0|(262145,[18098,19...|    59|\n",
            "|  0.0|(262145,[19036,23...|    62|\n",
            "|  0.0|(262145,[19036,25...|    50|\n",
            "|  1.0|(262145,[19633,21...|    19|\n",
            "|  0.0|(262145,[27707,65...|    38|\n",
            "|  0.0|(262145,[20891,27...|    51|\n",
            "|  0.0|(262145,[8287,120...|    20|\n",
            "+-----+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzfCQmrVNYCr"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeckHhg5NYCv",
        "outputId": "61b10450-eccd-41ab-f66b-45210cdcd94f"
      },
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|   class|                text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|negative|\"The burger... I ...|    86|  0.0|[\"the, burger...,...|[\"the, burger...,...|(262144,[19036,20...|(262144,[19036,20...|(262145,[19036,20...|[-874.20260546827...|[0.99999999999969...|       0.0|\n",
            "|negative|              #NAME?|     6|  0.0|            [#name?]|            [#name?]|(262144,[197050],...|(262144,[197050],...|(262145,[197050,2...|[-73.555070086084...|[0.64983564153590...|       0.0|\n",
            "|negative|A lady at the tab...|    75|  0.0|[a, lady, at, the...|[lady, table, nex...|(262144,[27576,33...|(262144,[27576,33...|(262145,[27576,33...|[-867.54957974144...|[0.99999999994769...|       0.0|\n",
            "|negative|After I pulled up...|    83|  0.0|[after, i, pulled...|[pulled, car, wai...|(262144,[9420,190...|(262144,[9420,190...|(262145,[9420,190...|[-845.91927612427...|[1.0,3.2119617294...|       0.0|\n",
            "|negative|After all the rav...|    82|  0.0|[after, all, the,...|[rave, reviews, w...|(262144,[9420,190...|(262144,[9420,190...|(262145,[9420,190...|[-786.27039416168...|[0.99999996135264...|       0.0|\n",
            "|negative|After two I felt ...|    28|  0.0|[after, two, i, f...|[two, felt, disgu...|(262144,[9420,190...|(262144,[9420,190...|(262145,[9420,190...|[-298.25949387934...|[0.99999978748199...|       0.0|\n",
            "|negative|All in all, Ha Lo...|    44|  0.0|[all, in, all,, h...|[all,, ha, long, ...|(262144,[20516,42...|(262144,[20516,42...|(262145,[20516,42...|[-578.83176854579...|[1.0,8.1435480175...|       0.0|\n",
            "|negative|Also, the fries a...|    66|  0.0|[also,, the, frie...|[also,, fries, wi...|(262144,[58267,66...|(262144,[58267,66...|(262145,[58267,66...|[-681.61988340372...|[1.0,1.9354527259...|       0.0|\n",
            "|negative|And it was way to...|    28|  0.0|[and, it, was, wa...|   [way, expensive.]|(262144,[27576,30...|(262144,[27576,30...|(262145,[27576,30...|[-244.85714319838...|[0.99978234381020...|       0.0|\n",
            "|negative|And the red curry...|    72|  0.0|[and, the, red, c...|[red, curry, much...|(262144,[10564,27...|(262144,[10564,27...|(262145,[10564,27...|[-782.07886946292...|[0.99981570181408...|       0.0|\n",
            "|negative|At least think to...|    84|  0.0|[at, least, think...|[least, think, re...|(262144,[6355,190...|(262144,[6355,190...|(262145,[6355,190...|[-928.92497070521...|[1.0,5.1475753604...|       0.0|\n",
            "|negative|Bland... Not a li...|   131|  0.0|[bland..., not, a...|[bland..., liking...|(262144,[7221,190...|(262144,[7221,190...|(262145,[7221,190...|[-1335.1569451033...|[1.0,3.2023202907...|       0.0|\n",
            "|negative|Boy was that suck...|    26|  0.0|[boy, was, that, ...|[boy, sucker, dry...|(262144,[48448,69...|(262144,[48448,69...|(262145,[48448,69...|[-321.42610814586...|[0.99999993730888...|       0.0|\n",
            "|negative|But the service w...|    31|  0.0|[but, the, servic...|[service, beyond,...|(262144,[33917,43...|(262144,[33917,43...|(262145,[33917,43...|[-271.20903166477...|[0.99964455064761...|       0.0|\n",
            "|negative|By this point, my...|   132|  0.0|[by, this, point,...|[point,, friends,...|(262144,[12035,19...|(262144,[12035,19...|(262145,[12035,19...|[-1369.5277234207...|[1.0,2.5279209842...|       0.0|\n",
            "|negative|By this time our ...|    80|  0.0|[by, this, time, ...|[time, side, rest...|(262144,[1061,232...|(262144,[1061,232...|(262145,[1061,232...|[-774.74290860717...|[7.06153906892756...|       1.0|\n",
            "|negative|Disappointing exp...|    25|  0.0|[disappointing, e...|[disappointing, e...|(262144,[55655,24...|(262144,[55655,24...|(262145,[55655,24...|[-173.64383481320...|[0.99999874819682...|       0.0|\n",
            "|negative|Don't bother comi...|    25|  0.0|[don't, bother, c...|[bother, coming, ...|(262144,[7221,124...|(262144,[7221,124...|(262145,[7221,124...|[-270.48465237115...|[0.98962907048592...|       0.0|\n",
            "|negative|     Don't do it!!!!|    15|  0.0| [don't, do, it!!!!]|            [it!!!!]|(262144,[3960,722...|(262144,[3960,722...|(262145,[3960,722...|[-191.48420185049...|[0.99999993089353...|       0.0|\n",
            "|negative|Don't waste your ...|    27|  0.0|[don't, waste, yo...|[waste, time, here.]|(262144,[7221,425...|(262144,[7221,425...|(262145,[7221,425...|[-274.17958305031...|[0.99999893650932...|       0.0|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVFrWcHINYCz",
        "outputId": "30f7eac6-6c4f-4ed3-8f06-692a0cfe9d04"
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.664437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOpKc638NlCQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}